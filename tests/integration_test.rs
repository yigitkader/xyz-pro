//! End-to-end integration tests
//!
//! Tests the complete pipeline: Generator ‚Üí Matcher ‚Üí Output
//! Uses known private keys with known addresses to verify correctness.

use xyz_pro::bridge::{KeyBatch, KeyGenerator, Matcher};
use xyz_pro::generator::{AddressEncoder, GeneratorConfig, GpuKeyGenerator, GpuGeneratorAdapter};
use xyz_pro::reader::{TargetSet, ParallelMatcher};

/// Known test vectors for Bitcoin addresses
/// Private key = 1 (0x0000000000000000000000000000000000000000000000000000000000000001)
mod test_vectors {
    /// Private key = 1 (Big Endian format - used in standard Bitcoin)
    pub const PRIVKEY_1_BE: [u8; 32] = [
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
    ];
    
    /// Private key = 1 (Little Endian format - used by GPU)
    pub const PRIVKEY_1_LE: [u8; 32] = [
        0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
    ];
    
    /// P2PKH address for private key 1 (compressed pubkey)
    pub const P2PKH_1: &str = "1BgGZ9tcN4rm9KBzDn7KprQz87SZ26SAMH";
    
    /// P2WPKH (bech32) address for private key 1
    pub const P2WPKH_1: &str = "bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4";
    
    /// P2SH (nested segwit) address for private key 1
    pub const P2SH_1: &str = "3JvL6Ymt8MVWiCNHC7oWU6nLeHNJKLZGLN";
    
    /// Hash160 of compressed pubkey for private key 1
    /// This is the pubkey hash used in P2PKH and P2WPKH addresses
    pub const PUBKEY_HASH_1: [u8; 20] = [
        0x75, 0x1e, 0x76, 0xe8, 0x19, 0x91, 0x96, 0xd4,
        0x54, 0x94, 0x1c, 0x45, 0xd1, 0xb3, 0xa3, 0x23,
        0xf1, 0x43, 0x3b, 0xd6,
    ];
}

/// Test that the address encoder produces correct addresses
#[test]
fn test_address_encoder_known_vectors() {
    use k256::elliptic_curve::sec1::ToEncodedPoint;
    use k256::SecretKey;
    use sha2::{Sha256, Digest};
    use ripemd::Ripemd160;
    
    // Create secret key from private key 1 (Big Endian format)
    let secret_key = SecretKey::from_bytes((&test_vectors::PRIVKEY_1_BE).into())
        .expect("Valid private key");
    
    // Get compressed public key
    let public_key = secret_key.public_key();
    let pubkey_bytes = public_key.to_encoded_point(true);
    let pubkey_compressed = pubkey_bytes.as_bytes();
    
    // Compute HASH160(pubkey)
    let sha256 = Sha256::digest(pubkey_compressed);
    let hash160 = Ripemd160::digest(&sha256);
    
    // Verify the hash160 matches our expected value
    let mut hash160_arr = [0u8; 20];
    hash160_arr.copy_from_slice(&hash160);
    
    assert_eq!(
        hash160_arr, 
        test_vectors::PUBKEY_HASH_1,
        "Hash160 of pubkey should match known value"
    );
    
    // Now test the encoder
    let mut encoder = AddressEncoder::new();
    
    // Create RawKeyData with our test values (Big Endian)
    let raw = xyz_pro::generator::RawKeyData {
        private_key: test_vectors::PRIVKEY_1_BE,
        pubkey_hash: hash160_arr,
        p2sh_hash: [0u8; 20],
    };
    
    let entry = encoder.encode(&raw);
    
    // Verify private key hex (Big Endian)
    assert_eq!(
        entry.private_key,
        "0000000000000000000000000000000000000000000000000000000000000001",
        "Private key hex should match"
    );
    
    // Verify P2PKH address
    assert_eq!(
        entry.p2pkh,
        test_vectors::P2PKH_1,
        "P2PKH address should match known value"
    );
    
    // Verify P2WPKH address
    assert_eq!(
        entry.p2wpkh,
        test_vectors::P2WPKH_1,
        "P2WPKH address should match known value"
    );
    
    println!("‚úÖ Address encoder produces correct addresses");
    println!("   Private key: {}", entry.private_key);
    println!("   P2PKH:  {}", entry.p2pkh);
    println!("   P2SH:   {}", entry.p2sh);
    println!("   P2WPKH: {}", entry.p2wpkh);
}

/// Test that TargetSet correctly loads and matches addresses
#[test]
fn test_target_set_matching() {
    // Load test targets
    let targets = TargetSet::load("test_targets.json")
        .expect("Failed to load test_targets.json");
    
    println!("üìÇ Loaded {} targets", targets.stats.total);
    
    // Check that our known hash160 is in the target set
    let found = targets.contains_hash160(&test_vectors::PUBKEY_HASH_1);
    
    assert!(
        found,
        "Target set should contain hash160 for private key 1 (P2PKH/P2WPKH)"
    );
    
    println!("‚úÖ Target set correctly identifies known address hash");
}

/// Test the complete matching pipeline with known private key
#[test]
fn test_end_to_end_matching() {
    use k256::elliptic_curve::sec1::ToEncodedPoint;
    use k256::SecretKey;
    use sha2::{Sha256, Digest};
    use ripemd::Ripemd160;
    
    // 1. Load targets
    let targets = TargetSet::load("test_targets.json")
        .expect("Failed to load test_targets.json");
    
    println!("üìÇ Loaded {} targets", targets.stats.total);
    
    // 2. Compute the hashes for private key 1 (simulating what GPU would do)
    let secret_key = SecretKey::from_bytes((&test_vectors::PRIVKEY_1_BE).into())
        .expect("Valid private key");
    
    let public_key = secret_key.public_key();
    let pubkey_bytes = public_key.to_encoded_point(true);
    let pubkey_compressed = pubkey_bytes.as_bytes();
    
    // HASH160(pubkey) for P2PKH/P2WPKH
    let sha256 = Sha256::digest(pubkey_compressed);
    let hash160 = Ripemd160::digest(&sha256);
    let mut pubkey_hash = [0u8; 20];
    pubkey_hash.copy_from_slice(&hash160);
    
    // P2SH hash: HASH160(OP_0 || PUSH20 || pubkey_hash)
    let mut witness_script = [0u8; 22];
    witness_script[0] = 0x00; // OP_0
    witness_script[1] = 0x14; // PUSH20
    witness_script[2..22].copy_from_slice(&pubkey_hash);
    
    let sha256_ws = Sha256::digest(&witness_script);
    let hash160_ws = Ripemd160::digest(&sha256_ws);
    let mut p2sh_hash = [0u8; 20];
    p2sh_hash.copy_from_slice(&hash160_ws);
    
    // 3. Check against targets
    let (p2pkh_match, p2sh_match, p2wpkh_match) = targets.check_raw(&pubkey_hash, &p2sh_hash);
    
    println!("üîç Checking private key 1:");
    println!("   P2PKH match:  {}", p2pkh_match);
    println!("   P2SH match:   {}", p2sh_match);
    println!("   P2WPKH match: {}", p2wpkh_match);
    
    // At least P2PKH or P2WPKH should match (they share the same hash160)
    assert!(
        p2pkh_match || p2wpkh_match,
        "Private key 1 should match P2PKH or P2WPKH target"
    );
    
    println!("‚úÖ End-to-end matching works correctly!");
}

/// Test GPU generator produces valid keys
#[test]
fn test_gpu_generator_produces_keys() {
    // Skip if GPU not available
    let config = GeneratorConfig {
        start_offset: 1,
        batch_size: 100,
        ..Default::default()
    };
    
    let gpu = match GpuKeyGenerator::new(config) {
        Ok(g) => g,
        Err(e) => {
            println!("‚ö†Ô∏è GPU not available, skipping test: {}", e);
            return;
        }
    };
    
    // Create adapter to get generated keys
    let adapter = GpuGeneratorAdapter::new(gpu);
    
    // Generate first batch
    let batch_bytes = match adapter.generate_batch() {
        Ok(b) => b,
        Err(e) => {
            println!("‚ö†Ô∏è Failed to generate batch: {}", e);
            return;
        }
    };
    
    let batch = KeyBatch::new(batch_bytes);
    
    println!("üéÆ GPU generated {} keys", batch.len());
    
    // Verify we got some keys
    assert!(batch.len() > 0, "Should generate at least one key");
    
    // Check first key is valid (non-zero)
    let first_key = batch.iter().next().unwrap();
    
    println!("   First key privkey: {}", hex::encode(first_key.private_key));
    println!("   First key hash160: {}", hex::encode(first_key.pubkey_hash));
    
    // Private key should not be all zeros
    assert!(
        !first_key.private_key.iter().all(|&b| b == 0),
        "Private key should not be all zeros"
    );
    
    // Hash160 should not be all zeros (computed from pubkey)
    assert!(
        !first_key.pubkey_hash.iter().all(|&b| b == 0),
        "Hash160 should not be all zeros"
    );
    
    println!("‚úÖ GPU generator produces valid keys!");
}

/// Full integration test: Generate keys and check matching works
/// This test verifies the pipeline functionality (GPU ‚Üí Matcher ‚Üí Output)
/// without depending on specific private key values
#[test]
fn test_full_pipeline_integration() {
    // 1. Load targets
    let matcher = match ParallelMatcher::load("test_targets.json") {
        Ok(m) => m,
        Err(e) => {
            println!("‚ö†Ô∏è Failed to load targets: {}", e);
            return;
        }
    };
    
    println!("üìÇ Matcher loaded with {} targets", matcher.target_count());
    
    // 2. Initialize GPU generator
    let config = GeneratorConfig {
        start_offset: 1,
        batch_size: 100,
        ..Default::default()
    };
    
    let gpu = match GpuKeyGenerator::new(config) {
        Ok(g) => g,
        Err(e) => {
            println!("‚ö†Ô∏è GPU not available, skipping test: {}", e);
            return;
        }
    };
    
    let adapter = GpuGeneratorAdapter::new(gpu);
    
    // 3. Generate and check
    let batch_bytes = match adapter.generate_batch() {
        Ok(b) => b,
        Err(e) => {
            println!("‚ö†Ô∏è Failed to generate batch: {}", e);
            return;
        }
    };
    
    let key_batch = KeyBatch::new(batch_bytes);
    
    // Verify batch is valid
    assert!(key_batch.len() > 0, "Batch should contain keys");
    
    // Check batch against targets
    let matches = matcher.check_batch(&key_batch);
    
    println!("üîç Generated {} keys, found {} matches", key_batch.len(), matches.len());
    
    for m in &matches {
        println!("   üéØ MATCH: privkey={}", hex::encode(m.key.private_key));
    }
    
    // Verify matching logic works (even if no matches found with random keys)
    // The important thing is that check_batch runs without error
    println!("‚úÖ Pipeline integration test passed!");
    println!("   GPU generation: OK");
    println!("   Batch creation: OK");
    println!("   Matching logic: OK");
    println!("   Matches found: {}", matches.len());
}

/// Test that we can find matches for ALL 3 address types using CPU-computed keys
/// This directly tests the matching logic with known good data for:
/// - P2PKH (1BgGZ9tcN4rm9KBzDn7KprQz87SZ26SAMH)
/// - P2SH  (3JvL6Ymt8MVWiCNHC7oWU6nLeHNJKLZGLN)
/// - P2WPKH (bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4)
#[test]
fn test_matching_all_three_address_types() {
    use k256::elliptic_curve::sec1::ToEncodedPoint;
    use k256::SecretKey;
    use sha2::{Sha256, Digest};
    use ripemd::Ripemd160;
    use xyz_pro::bridge::MatchType;
    
    // 1. Load targets
    let matcher = match ParallelMatcher::load("test_targets.json") {
        Ok(m) => m,
        Err(e) => {
            println!("‚ö†Ô∏è Failed to load targets: {}", e);
            return;
        }
    };
    
    println!("üìÇ Matcher loaded with {} targets", matcher.target_count());
    println!("   P2PKH targets: {}", matcher.stats().p2pkh);
    println!("   P2SH targets:  {}", matcher.stats().p2sh);
    println!("   P2WPKH targets: {}", matcher.stats().p2wpkh);
    
    // 2. Create a key entry for private key 1 manually
    let secret_key = SecretKey::from_bytes((&test_vectors::PRIVKEY_1_BE).into())
        .expect("Valid private key");
    
    let public_key = secret_key.public_key();
    let pubkey_bytes = public_key.to_encoded_point(true);
    let pubkey_compressed = pubkey_bytes.as_bytes();
    
    // HASH160(pubkey) - used for P2PKH and P2WPKH
    let sha256 = Sha256::digest(pubkey_compressed);
    let hash160 = Ripemd160::digest(&sha256);
    let mut pubkey_hash = [0u8; 20];
    pubkey_hash.copy_from_slice(&hash160);
    
    println!("üîë Private key 1 computed hashes:");
    println!("   pubkey_hash (P2PKH/P2WPKH): {}", hex::encode(pubkey_hash));
    
    // P2SH hash: HASH160(OP_0 || PUSH20 || pubkey_hash)
    // This is the script hash for nested SegWit (P2SH-P2WPKH)
    let mut witness_script = [0u8; 22];
    witness_script[0] = 0x00; // OP_0
    witness_script[1] = 0x14; // PUSH20 (20 bytes)
    witness_script[2..22].copy_from_slice(&pubkey_hash);
    
    let sha256_ws = Sha256::digest(&witness_script);
    let hash160_ws = Ripemd160::digest(&sha256_ws);
    let mut p2sh_hash = [0u8; 20];
    p2sh_hash.copy_from_slice(&hash160_ws);
    
    println!("   p2sh_hash (P2SH):            {}", hex::encode(p2sh_hash));
    
    // 3. Use check_key directly to get ALL match types (not just first one)
    // ParallelMatcher.check_batch only returns first match, but check_key returns all
    let match_types = matcher.check_key(&pubkey_hash, &p2sh_hash);
    
    println!("\nüîç Testing ALL 3 address types for private key 1:");
    println!("   Expected addresses in test_targets.json:");
    println!("   - P2PKH:  {}", test_vectors::P2PKH_1);
    println!("   - P2SH:   {}", test_vectors::P2SH_1);
    println!("   - P2WPKH: {}", test_vectors::P2WPKH_1);
    println!("\n   Match types found: {:?}", match_types);
    
    // Track which types we found
    let mut found_p2pkh = false;
    let mut found_p2sh = false;
    let mut found_p2wpkh = false;
    
    for mt in &match_types {
        match mt {
            MatchType::P2PKH => {
                found_p2pkh = true;
                println!("   ‚úÖ P2PKH match found!");
            }
            MatchType::P2SH => {
                found_p2sh = true;
                println!("   ‚úÖ P2SH match found!");
            }
            MatchType::P2WPKH => {
                found_p2wpkh = true;
                println!("   ‚úÖ P2WPKH match found!");
            }
        }
    }
    
    // Verify all 3 types were matched
    assert!(found_p2pkh, "P2PKH address should match (1BgGZ9tcN4rm9KBzDn7KprQz87SZ26SAMH)");
    assert!(found_p2sh, "P2SH address should match (3JvL6Ymt8MVWiCNHC7oWU6nLeHNJKLZGLN)");
    assert!(found_p2wpkh, "P2WPKH address should match (bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4)");
    
    println!("\nüéØ ALL 3 ADDRESS TYPES MATCHED SUCCESSFULLY!");
    println!("   ‚úÖ P2PKH  (Legacy)           - 1BgGZ9...");
    println!("   ‚úÖ P2SH   (Nested SegWit)    - 3JvL6Y...");
    println!("   ‚úÖ P2WPKH (Native SegWit)    - bc1qw5...");
}

/// Test GLV Lambda transformation is mathematically correct
/// GLV uses Œª where Œª¬≥ ‚â° 1 (mod n) and Œ≤¬≥ ‚â° 1 (mod p)
/// For point P, œÜ(P) = (Œ≤¬∑x, y) corresponds to private key Œª¬∑k
#[test]
fn test_glv_lambda_transform() {
    use k256::Scalar;
    use k256::elliptic_curve::PrimeField;
    
    // GLV Lambda constant (from keygen.metal, stored as ulong4)
    // In Metal: {0xDF02967C1B23BD72, 0x122E22EA20816678, 0xA5261C028812645A, 0x5363AD4CC05C30E0}
    // where .x is LSW, .w is MSW
    // As 256-bit big-endian: 0x5363AD4CC05C30E0_A5261C028812645A_122E22EA20816678_DF02967C1B23BD72
    let lambda_bytes: [u8; 32] = [
        0x53, 0x63, 0xAD, 0x4C, 0xC0, 0x5C, 0x30, 0xE0,  // .w (MSW)
        0xA5, 0x26, 0x1C, 0x02, 0x88, 0x12, 0x64, 0x5A,  // .z
        0x12, 0x2E, 0x22, 0xEA, 0x20, 0x81, 0x66, 0x78,  // .y
        0xDF, 0x02, 0x96, 0x7C, 0x1B, 0x23, 0xBD, 0x72,  // .x (LSW)
    ];
    
    // Test that Œª¬≥ ‚â° 1 (mod n)
    // This is the fundamental property of GLV endomorphism
    let lambda = Scalar::from_repr(lambda_bytes.into()).unwrap();
    let lambda_sq = lambda * lambda;
    let lambda_cubed = lambda_sq * lambda;
    
    // Œª¬≥ should equal 1
    let one = Scalar::ONE;
    assert_eq!(
        lambda_cubed, one,
        "Œª¬≥ should equal 1 (mod n) for GLV endomorphism"
    );
    
    println!("‚úÖ GLV Lambda verification:");
    println!("   Œª¬≥ ‚â° 1 (mod n) verified");
    
    // Test scalar multiplication with multiple edge cases
    // This ensures scalar_mul_mod_n handles all ranges correctly
    
    println!("   Testing GLV transform with various k values:");
    
    // Helper to verify GLV transform
    let verify_glv = |k: Scalar, name: &str| {
        let glv_k = k * lambda;
        let lambda_sq = lambda * lambda;
        let recovered_k = glv_k * lambda_sq;
        assert_eq!(
            recovered_k, k,
            "(Œª¬∑k)¬∑Œª¬≤ should equal k for {}", name
        );
        println!("   ‚úì {} verified", name);
    };
    
    // Case 1: k = 1 (minimal)
    let k1 = Scalar::from_repr(test_vectors::PRIVKEY_1_BE.into()).unwrap();
    verify_glv(k1, "k = 1 (minimal)");
    
    // Case 2: k = 2^128 (128-bit boundary - tests carry across word boundary)
    let mut k128_bytes = [0u8; 32];
    k128_bytes[15] = 1; // 2^128 in big-endian
    let k128 = Scalar::from_repr(k128_bytes.into()).unwrap();
    verify_glv(k128, "k = 2^128 (word boundary)");
    
    // Case 3: k = 2^192 (tests upper half of 256-bit range)
    let mut k192_bytes = [0u8; 32];
    k192_bytes[7] = 1; // 2^192 in big-endian
    let k192 = Scalar::from_repr(k192_bytes.into()).unwrap();
    verify_glv(k192, "k = 2^192 (upper half)");
    
    // Case 4: k = n - 1 (maximum valid scalar, near curve order)
    // n = FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141
    let n_minus_1_bytes: [u8; 32] = [
        0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF,
        0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFE,
        0xBA, 0xAE, 0xDC, 0xE6, 0xAF, 0x48, 0xA0, 0x3B,
        0xBF, 0xD2, 0x5E, 0x8C, 0xD0, 0x36, 0x41, 0x40,
    ];
    let k_max = Scalar::from_repr(n_minus_1_bytes.into()).unwrap();
    verify_glv(k_max, "k = n-1 (maximum)");
    
    // Case 5: k = 0xFFFFFFFF...FFFF (all bits set, tests reduction)
    let k_allones_bytes = [0xFF; 32];
    // This will be reduced mod n automatically
    // Note: from_repr returns CtOption, use into_option() to convert
    let k_allones_opt: k256::elliptic_curve::subtle::CtOption<Scalar> = 
        Scalar::from_repr(k_allones_bytes.into());
    if k_allones_opt.is_some().into() {
        verify_glv(k_allones_opt.unwrap(), "k = 2^256-1 (all bits, reduced)");
    }
    
    // Case 6: Random large value (stress test)
    let k_random_bytes: [u8; 32] = [
        0x79, 0xBE, 0x66, 0x7E, 0xF9, 0xDC, 0xBB, 0xAC,
        0x55, 0xA0, 0x62, 0x95, 0xCE, 0x87, 0x0B, 0x07,
        0x02, 0x9B, 0xFC, 0xDB, 0x2D, 0xCE, 0x28, 0xD9,
        0x59, 0xF2, 0x81, 0x5B, 0x16, 0xF8, 0x17, 0x98,
    ];
    let k_random = Scalar::from_repr(k_random_bytes.into()).unwrap();
    verify_glv(k_random, "k = random large value");
    
    println!("‚úÖ GLV Lambda transform is mathematically correct for all edge cases!");
}

/// Test that GPU-computed hashes match CPU-computed hashes
/// This verifies the GPU's SHA256 and RIPEMD160 implementations
#[test]
fn test_gpu_hash_matches_cpu() {
    use k256::elliptic_curve::sec1::ToEncodedPoint;
    use k256::SecretKey;
    use sha2::{Sha256, Digest};
    use ripemd::Ripemd160;
    
    // Skip if GPU not available
    let config = GeneratorConfig {
        start_offset: 1,  // Start at private key 1
        batch_size: 32,
        ..Default::default()
    };
    
    let gpu = match GpuKeyGenerator::new(config) {
        Ok(g) => g,
        Err(e) => {
            println!("‚ö†Ô∏è GPU not available, skipping test: {}", e);
            return;
        }
    };
    
    let adapter = GpuGeneratorAdapter::new(gpu);
    
    // Generate keys starting from offset 1
    let batch_bytes = match adapter.generate_batch() {
        Ok(b) => b,
        Err(e) => {
            println!("‚ö†Ô∏è Failed to generate batch: {}", e);
            return;
        }
    };
    
    let batch = KeyBatch::new(batch_bytes);
    
    // Find a valid key to test
    let gpu_key = batch.iter()
        .find(|k| k.private_key.iter().any(|&b| b != 0))
        .expect("Should have at least one valid key");
    
    println!("üîç Testing GPU vs CPU hash computation:");
    println!("   GPU private key: {}", hex::encode(gpu_key.private_key));
    println!("   GPU pubkey_hash: {}", hex::encode(gpu_key.pubkey_hash));
    println!("   GPU p2sh_hash:   {}", hex::encode(gpu_key.p2sh_hash));
    
    // Compute the same hashes on CPU
    let secret_key = match SecretKey::from_bytes((&gpu_key.private_key).into()) {
        Ok(sk) => sk,
        Err(_) => {
            println!("‚ö†Ô∏è Invalid private key from GPU, skipping verification");
            return;
        }
    };
    
    let public_key = secret_key.public_key();
    let pubkey_bytes = public_key.to_encoded_point(true);
    let pubkey_compressed = pubkey_bytes.as_bytes();
    
    // HASH160(pubkey)
    let sha256 = Sha256::digest(pubkey_compressed);
    let hash160 = Ripemd160::digest(&sha256);
    let mut cpu_pubkey_hash = [0u8; 20];
    cpu_pubkey_hash.copy_from_slice(&hash160);
    
    // P2SH hash
    let mut witness_script = [0u8; 22];
    witness_script[0] = 0x00;
    witness_script[1] = 0x14;
    witness_script[2..22].copy_from_slice(&cpu_pubkey_hash);
    
    let sha256_ws = Sha256::digest(&witness_script);
    let hash160_ws = Ripemd160::digest(&sha256_ws);
    let mut cpu_p2sh_hash = [0u8; 20];
    cpu_p2sh_hash.copy_from_slice(&hash160_ws);
    
    println!("   CPU pubkey_hash: {}", hex::encode(cpu_pubkey_hash));
    println!("   CPU p2sh_hash:   {}", hex::encode(cpu_p2sh_hash));
    
    // Verify hashes match
    assert_eq!(
        gpu_key.pubkey_hash, cpu_pubkey_hash,
        "GPU and CPU pubkey_hash should match"
    );
    
    assert_eq!(
        gpu_key.p2sh_hash, cpu_p2sh_hash,
        "GPU and CPU p2sh_hash should match"
    );
    
    println!("‚úÖ GPU hash computation matches CPU!");
}

/// Test GPU GLV scalar multiplication matches CPU
/// This is the critical test - verifies that GPU computes Œª¬∑k (mod n) correctly
#[test]
fn test_gpu_glv_scalar_matches_cpu() {
    use k256::Scalar;
    use k256::elliptic_curve::PrimeField;
    use k256::SecretKey;
    
    // GLV Lambda (same as in keygen.metal)
    // Metal: {0xDF02967C1B23BD72, 0x122E22EA20816678, 0xA5261C028812645A, 0x5363AD4CC05C30E0}
    // where .x=LSW, .w=MSW
    let lambda_bytes: [u8; 32] = [
        0x53, 0x63, 0xAD, 0x4C, 0xC0, 0x5C, 0x30, 0xE0,  // .w (MSW)
        0xA5, 0x26, 0x1C, 0x02, 0x88, 0x12, 0x64, 0x5A,  // .z
        0x12, 0x2E, 0x22, 0xEA, 0x20, 0x81, 0x66, 0x78,  // .y
        0xDF, 0x02, 0x96, 0x7C, 0x1B, 0x23, 0xBD, 0x72,  // .x (LSW)
    ];
    let lambda = Scalar::from_repr(lambda_bytes.into()).unwrap();
    
    // Skip if GPU not available
    let config = GeneratorConfig {
        start_offset: 100,  // Start at non-trivial offset
        batch_size: 32,
        ..Default::default()
    };
    
    let gpu = match GpuKeyGenerator::new(config) {
        Ok(g) => g,
        Err(e) => {
            println!("‚ö†Ô∏è GPU not available, skipping test: {}", e);
            return;
        }
    };
    
    // Use adapter to get batch (it handles dispatch_glv internally)
    let adapter = GpuGeneratorAdapter::new(gpu);
    
    let batch_bytes = match adapter.generate_batch() {
        Ok(b) => b,
        Err(e) => {
            println!("‚ö†Ô∏è Failed to generate batch: {}", e);
            return;
        }
    };
    
    let batch = KeyBatch::new(batch_bytes);
    
    println!("üîç Testing GPU GLV scalar multiplication:");
    println!("   Batch size: {} keys", batch.len());
    
    if batch.len() < 2 {
        println!("‚ö†Ô∏è Not enough keys in batch, skipping");
        return;
    }
    
    // GLV kernel outputs pairs: [primary_0, glv_0, primary_1, glv_1, ...]
    // Collect to Vec for indexed access
    let keys: Vec<_> = batch.iter().collect();
    
    // Check first valid pair
    let mut found_pair = false;
    for i in (0..keys.len().saturating_sub(1)).step_by(2) {
        let primary = &keys[i];
        let glv = &keys[i + 1];
        
        // Skip if either key is zero
        if primary.private_key.iter().all(|&b| b == 0) || 
           glv.private_key.iter().all(|&b| b == 0) {
            continue;
        }
        
        println!("   Primary key: {}", hex::encode(primary.private_key));
        println!("   GLV key:     {}", hex::encode(glv.private_key));
        
        // CPU compute: glv_k = primary_k * lambda (mod n)
        let primary_scalar = match Scalar::from_repr(primary.private_key.into()) {
            opt if opt.is_some().into() => opt.unwrap(),
            _ => continue,
        };
        
        let cpu_glv_scalar = primary_scalar * lambda;
        let cpu_glv_bytes: [u8; 32] = cpu_glv_scalar.to_repr().into();
        
        println!("   CPU GLV:     {}", hex::encode(cpu_glv_bytes));
        
        // Verify GPU GLV matches CPU
        assert_eq!(
            glv.private_key, cpu_glv_bytes,
            "GPU GLV private key should match CPU computation"
        );
        
        // Also verify the GLV key produces the correct address
        // (this tests the endomorphism property: œÜ(P) has privkey Œª¬∑k)
        if let Ok(primary_sk) = SecretKey::from_bytes((&primary.private_key).into()) {
            if let Ok(glv_sk) = SecretKey::from_bytes((&glv.private_key).into()) {
                use k256::elliptic_curve::sec1::ToEncodedPoint;
                
                let primary_pk = primary_sk.public_key();
                let glv_pk = glv_sk.public_key();
                
                // GLV beta constant: Œ≤¬≥ ‚â° 1 (mod p)
                // œÜ(x, y) = (Œ≤¬∑x, y)
                // The y-coordinates should be the same
                let primary_point = primary_pk.to_encoded_point(false);
                let glv_point = glv_pk.to_encoded_point(false);
                
                // y-coordinate is bytes 33-64 in uncompressed format
                let primary_y = &primary_point.as_bytes()[33..65];
                let glv_y = &glv_point.as_bytes()[33..65];
                
                assert_eq!(
                    primary_y, glv_y,
                    "GLV endomorphism should preserve y-coordinate"
                );
                
                println!("   ‚úì Y-coordinates match (endomorphism verified)");
            }
        }
        
        found_pair = true;
        break;
    }
    
    if !found_pair {
        println!("‚ö†Ô∏è No valid key pairs found in batch");
        return;
    }
    
    println!("‚úÖ GPU GLV scalar multiplication matches CPU!");
}

/// Test that the address encoder handles edge cases
#[test]
fn test_encoder_edge_cases() {
    let mut encoder = AddressEncoder::new();
    
    // Test with zero hash (edge case)
    let raw_zero = xyz_pro::generator::RawKeyData {
        private_key: [0u8; 32],
        pubkey_hash: [0u8; 20],
        p2sh_hash: [0u8; 20],
    };
    
    let entry = encoder.encode(&raw_zero);
    
    // All addresses should be valid format
    assert!(entry.p2pkh.starts_with('1'), "P2PKH should start with 1");
    assert!(entry.p2sh.starts_with('3'), "P2SH should start with 3");
    assert!(entry.p2wpkh.starts_with("bc1q"), "P2WPKH should start with bc1q");
    
    println!("‚úÖ Encoder handles edge cases correctly");
}

/// Test cache functionality for TargetSet
#[test]
fn test_target_set_caching() {
    use std::time::Instant;
    
    // First load - should parse JSON
    let start1 = Instant::now();
    let targets1 = TargetSet::load("test_targets.json")
        .expect("Failed to load test_targets.json");
    let time1 = start1.elapsed();
    
    println!("üìÇ First load: {} targets in {:?}", targets1.stats.total, time1);
    
    // Second load - should use cache
    let start2 = Instant::now();
    let targets2 = TargetSet::load("test_targets.json")
        .expect("Failed to load test_targets.json (cached)");
    let time2 = start2.elapsed();
    
    println!("‚ö° Cached load: {} targets in {:?}", targets2.stats.total, time2);
    
    // Both should have same target count
    assert_eq!(
        targets1.stats.total,
        targets2.stats.total,
        "Cached load should have same target count"
    );
    
    // Cached load should be faster (or at least similar)
    // We don't assert this strictly as it depends on system state
    println!("‚úÖ Cache system works correctly");
}

// =============================================================================
// EDGE CASE TESTS
// =============================================================================

/// Test RawKeyData with all-zero private key (invalid)
#[test]
fn test_edge_case_zero_private_key() {
    let raw = xyz_pro::generator::RawKeyData {
        private_key: [0u8; 32],
        pubkey_hash: [0u8; 20],
        p2sh_hash: [0u8; 20],
    };
    
    // Zero private key is invalid
    assert!(!raw.is_valid(), "Zero private key should be invalid");
    println!("‚úÖ Zero private key correctly rejected");
}

/// Test RawKeyData with maximum valid private key (n-1)
#[test]
fn test_edge_case_max_private_key() {
    // n-1 = FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364140
    let max_key: [u8; 32] = [
        0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF,
        0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFE,
        0xBA, 0xAE, 0xDC, 0xE6, 0xAF, 0x48, 0xA0, 0x3B,
        0xBF, 0xD2, 0x5E, 0x8C, 0xD0, 0x36, 0x41, 0x40,
    ];
    
    let raw = xyz_pro::generator::RawKeyData {
        private_key: max_key,
        pubkey_hash: [0xFF; 20],
        p2sh_hash: [0xFF; 20],
    };
    
    // Max key is valid (non-zero)
    assert!(raw.is_valid(), "Max private key should be valid");
    println!("‚úÖ Maximum private key (n-1) accepted");
}

/// Test RawKeyData::from_bytes with various sizes
#[test]
fn test_edge_case_raw_key_data_sizes() {
    // Exactly 72 bytes - should work
    let data_72 = vec![0x42u8; 72];
    let raw = xyz_pro::generator::RawKeyData::from_bytes(&data_72);
    assert!(raw.is_some(), "72 bytes should be valid");
    
    // Less than 72 bytes - should fail
    let data_71 = vec![0x42u8; 71];
    let raw = xyz_pro::generator::RawKeyData::from_bytes(&data_71);
    assert!(raw.is_none(), "71 bytes should be invalid");
    
    // More than 72 bytes - should work (uses first 72)
    let data_100 = vec![0x42u8; 100];
    let raw = xyz_pro::generator::RawKeyData::from_bytes(&data_100);
    assert!(raw.is_some(), "100 bytes should work (uses first 72)");
    
    println!("‚úÖ RawKeyData::from_bytes handles edge sizes correctly");
}

/// Test address encoding with all-0xFF hash (boundary)
#[test]
fn test_edge_case_max_hash_encoding() {
    let mut encoder = AddressEncoder::new();
    
    let raw = xyz_pro::generator::RawKeyData {
        private_key: [0xFF; 32],
        pubkey_hash: [0xFF; 20],
        p2sh_hash: [0xFF; 20],
    };
    
    let entry = encoder.encode(&raw);
    
    // All addresses should still be valid format
    assert!(entry.p2pkh.starts_with('1'), "P2PKH should start with 1");
    assert!(entry.p2sh.starts_with('3'), "P2SH should start with 3");
    assert!(entry.p2wpkh.starts_with("bc1q"), "P2WPKH should start with bc1q");
    
    // Verify lengths are reasonable
    assert!(entry.p2pkh.len() >= 25 && entry.p2pkh.len() <= 34, "P2PKH length should be valid");
    assert!(entry.p2sh.len() >= 25 && entry.p2sh.len() <= 35, "P2SH length should be valid");
    assert!(entry.p2wpkh.len() >= 42 && entry.p2wpkh.len() <= 62, "P2WPKH length should be valid");
    
    println!("‚úÖ Max hash (0xFF) encoding produces valid addresses");
    println!("   P2PKH:  {} (len={})", entry.p2pkh, entry.p2pkh.len());
    println!("   P2SH:   {} (len={})", entry.p2sh, entry.p2sh.len());
    println!("   P2WPKH: {} (len={})", entry.p2wpkh, entry.p2wpkh.len());
}

/// Test GLV scalar multiplication with edge values
#[test]
fn test_edge_case_glv_scalar_mul() {
    use k256::Scalar;
    use k256::elliptic_curve::PrimeField;
    
    // GLV Lambda
    let lambda_bytes: [u8; 32] = [
        0x53, 0x63, 0xAD, 0x4C, 0xC0, 0x5C, 0x30, 0xE0,
        0xA5, 0x26, 0x1C, 0x02, 0x88, 0x12, 0x64, 0x5A,
        0x12, 0x2E, 0x22, 0xEA, 0x20, 0x81, 0x66, 0x78,
        0xDF, 0x02, 0x96, 0x7C, 0x1B, 0x23, 0xBD, 0x72,
    ];
    let lambda = Scalar::from_repr(lambda_bytes.into()).unwrap();
    
    // Test cases that stress carry propagation in scalar_mul_mod_n
    let test_cases: Vec<(&str, [u8; 32])> = vec![
        // All ones in each word boundary
        ("0x00...00FF (byte 31)", {
            let mut k = [0u8; 32];
            k[31] = 0xFF;
            k
        }),
        ("0x00...FF00 (byte 30)", {
            let mut k = [0u8; 32];
            k[30] = 0xFF;
            k
        }),
        // Word boundaries (64-bit)
        ("0x00...00FFFFFFFF (lower 32 bits)", {
            let mut k = [0u8; 32];
            k[28..32].copy_from_slice(&[0xFF, 0xFF, 0xFF, 0xFF]);
            k
        }),
        // 128-bit boundary
        ("0x00...FFFFFFFF...0 (bits 128-159)", {
            let mut k = [0u8; 32];
            k[12..16].copy_from_slice(&[0xFF, 0xFF, 0xFF, 0xFF]);
            k
        }),
        // Alternating bits (stress test)
        ("0xAAAA...AAAA", {
            [0xAA; 32]
        }),
        ("0x5555...5555", {
            [0x55; 32]
        }),
    ];
    
    println!("üß™ Testing GLV scalar multiplication edge cases:");
    
    for (name, k_bytes) in test_cases {
        let k_opt: k256::elliptic_curve::subtle::CtOption<Scalar> = 
            Scalar::from_repr(k_bytes.into());
        if !bool::from(k_opt.is_some()) {
            continue; // Skip if not valid scalar
        }
        let k = k_opt.unwrap();
        
        // Verify: (Œª¬∑k)¬∑Œª¬≤ = k
        let glv_k = k * lambda;
        let lambda_sq = lambda * lambda;
        let recovered_k = glv_k * lambda_sq;
        
        assert_eq!(
            recovered_k, k,
            "GLV transform should be reversible for {}", name
        );
        println!("   ‚úì {}", name);
    }
    
    println!("‚úÖ All GLV scalar multiplication edge cases passed");
}

/// Test XOR filter with potential collision scenarios
#[test]
fn test_edge_case_xor_filter_collisions() {
    use std::collections::HashSet;
    
    // Generate hashes that could potentially collide in XOR-fold
    // XOR-fold: p1 ^ p2 ^ p3 where p1,p2=8 bytes, p3=4 bytes
    
    // Two different hashes that XOR-fold to same value:
    // hash1: [A, B, C] -> A ^ B ^ C
    // hash2: [A', B', C'] where A' ^ B' ^ C' = A ^ B ^ C
    
    let hash1: [u8; 20] = [
        0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88,  // p1
        0xAA, 0xBB, 0xCC, 0xDD, 0xEE, 0xFF, 0x00, 0x11,  // p2
        0x12, 0x34, 0x56, 0x78,                          // p3
    ];
    
    // Construct hash2 that XOR-folds to same value as hash1
    // by swapping bits between p1 and p2
    let hash2: [u8; 20] = [
        0xAA, 0xBB, 0xCC, 0xDD, 0xEE, 0xFF, 0x00, 0x11,  // swapped p1
        0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88,  // swapped p2
        0x12, 0x34, 0x56, 0x78,                          // same p3
    ];
    
    // These should XOR-fold to the same value but be different hashes
    fn xor_fold(hash: &[u8; 20]) -> u64 {
        let p1 = u64::from_le_bytes(hash[0..8].try_into().unwrap());
        let p2 = u64::from_le_bytes(hash[8..16].try_into().unwrap());
        let p3 = u32::from_le_bytes(hash[16..20].try_into().unwrap()) as u64;
        p1 ^ p2 ^ p3
    }
    
    let fold1 = xor_fold(&hash1);
    let fold2 = xor_fold(&hash2);
    
    // Verify they fold to same value (potential collision)
    assert_eq!(fold1, fold2, "These hashes should XOR-fold to same value");
    
    // But the actual hashes are different
    assert_ne!(hash1, hash2, "The actual hashes should be different");
    
    // This is why XOR filter uses HashSet as fallback!
    let mut set: HashSet<[u8; 20]> = HashSet::new();
    set.insert(hash1);
    
    // XOR filter would say "maybe" for hash2, but HashSet correctly rejects
    assert!(set.contains(&hash1), "HashSet should contain hash1");
    assert!(!set.contains(&hash2), "HashSet should NOT contain hash2 (collision handled)");
    
    println!("‚úÖ XOR filter collision scenario correctly handled by HashSet fallback");
    println!("   hash1 XOR-fold: 0x{:016X}", fold1);
    println!("   hash2 XOR-fold: 0x{:016X}", fold2);
    println!("   Both fold to same value but HashSet distinguishes them");
}

/// Test KeyBatch iteration with various sizes
#[test]
fn test_edge_case_key_batch_sizes() {
    use xyz_pro::bridge::KeyBatch;
    use xyz_pro::generator::RawKeyData;
    
    // Empty batch
    let empty_data: Vec<u8> = vec![];
    let empty_batch = KeyBatch::new(&empty_data);
    assert_eq!(empty_batch.len(), 0, "Empty batch should have 0 keys");
    
    // Single key
    let single_data = vec![0x42u8; RawKeyData::SIZE];
    let single_batch = KeyBatch::new(&single_data);
    assert_eq!(single_batch.len(), 1, "Single key batch should have 1 key");
    
    // Partial key (should be truncated)
    let partial_data = vec![0x42u8; RawKeyData::SIZE + 10];
    let partial_batch = KeyBatch::new(&partial_data);
    assert_eq!(partial_batch.len(), 1, "Partial extra bytes should be ignored");
    
    // Large batch
    let large_data = vec![0x42u8; RawKeyData::SIZE * 1000];
    let large_batch = KeyBatch::new(&large_data);
    assert_eq!(large_batch.len(), 1000, "Large batch should have 1000 keys");
    
    println!("‚úÖ KeyBatch handles all size edge cases correctly");
}

/// Test GPU output format matches expected layout
#[test]
fn test_edge_case_gpu_output_layout() {
    use xyz_pro::generator::RawKeyData;
    
    // GPU output format: [privkey:32][pubkey_hash:20][p2sh_hash:20] = 72 bytes
    assert_eq!(RawKeyData::SIZE, 72, "RawKeyData should be exactly 72 bytes");
    
    // Test struct layout
    let raw = RawKeyData {
        private_key: [0x11; 32],
        pubkey_hash: [0x22; 20],
        p2sh_hash: [0x33; 20],
    };
    
    // Verify field offsets by reconstructing from bytes
    let reconstructed = RawKeyData::from_bytes(&[
        // 32 bytes private key
        0x11, 0x11, 0x11, 0x11, 0x11, 0x11, 0x11, 0x11,
        0x11, 0x11, 0x11, 0x11, 0x11, 0x11, 0x11, 0x11,
        0x11, 0x11, 0x11, 0x11, 0x11, 0x11, 0x11, 0x11,
        0x11, 0x11, 0x11, 0x11, 0x11, 0x11, 0x11, 0x11,
        // 20 bytes pubkey_hash
        0x22, 0x22, 0x22, 0x22, 0x22, 0x22, 0x22, 0x22,
        0x22, 0x22, 0x22, 0x22, 0x22, 0x22, 0x22, 0x22,
        0x22, 0x22, 0x22, 0x22,
        // 20 bytes p2sh_hash
        0x33, 0x33, 0x33, 0x33, 0x33, 0x33, 0x33, 0x33,
        0x33, 0x33, 0x33, 0x33, 0x33, 0x33, 0x33, 0x33,
        0x33, 0x33, 0x33, 0x33,
    ]).expect("Should parse 72 bytes");
    
    assert_eq!(raw.private_key, reconstructed.private_key, "Private key layout mismatch");
    assert_eq!(raw.pubkey_hash, reconstructed.pubkey_hash, "Pubkey hash layout mismatch");
    assert_eq!(raw.p2sh_hash, reconstructed.p2sh_hash, "P2SH hash layout mismatch");
    
    println!("‚úÖ GPU output layout verified: [privkey:32][pubkey_hash:20][p2sh_hash:20]");
}

/// Test private key validation edge cases
#[test]
fn test_edge_case_privkey_validation() {
    // Test is_valid() with various patterns
    let test_cases: Vec<(&str, [u8; 32], bool)> = vec![
        ("All zeros", [0u8; 32], false),
        ("Single bit set (LSB)", {
            let mut k = [0u8; 32];
            k[31] = 0x01;
            k
        }, true),
        ("Single bit set (MSB)", {
            let mut k = [0u8; 32];
            k[0] = 0x80;
            k
        }, true),
        ("All ones", [0xFF; 32], true),
        ("Only middle byte set", {
            let mut k = [0u8; 32];
            k[16] = 0x42;
            k
        }, true),
    ];
    
    println!("üß™ Testing private key validation edge cases:");
    
    for (name, privkey, expected_valid) in test_cases {
        let raw = xyz_pro::generator::RawKeyData {
            private_key: privkey,
            pubkey_hash: [0u8; 20],
            p2sh_hash: [0u8; 20],
        };
        
        let is_valid = raw.is_valid();
        assert_eq!(
            is_valid, expected_valid,
            "{}: expected valid={}, got valid={}", name, expected_valid, is_valid
        );
        println!("   ‚úì {}: valid={}", name, is_valid);
    }
    
    println!("‚úÖ All private key validation edge cases passed");
}

/// Test GLV scalar multiplication with values that trigger carry=2 scenario
/// In schoolbook multiplication: c = c2 + c3 can be 0, 1, or 2
/// When c=2, proper carry propagation through upper words is critical
#[test]
fn test_glv_carry_propagation() {
    use k256::Scalar;
    use k256::elliptic_curve::PrimeField;
    
    // GLV Lambda constant
    let lambda_bytes: [u8; 32] = [
        0x53, 0x63, 0xAD, 0x4C, 0xC0, 0x5C, 0x30, 0xE0,
        0xA5, 0x26, 0x1C, 0x02, 0x88, 0x12, 0x64, 0x5A,
        0x12, 0x2E, 0x22, 0xEA, 0x20, 0x81, 0x66, 0x78,
        0xDF, 0x02, 0x96, 0x7C, 0x1B, 0x23, 0xBD, 0x72,
    ];
    let lambda = Scalar::from_repr(lambda_bytes.into()).unwrap();
    let lambda_sq = lambda * lambda;
    
    // Test cases specifically designed to trigger carry=2 in multiplication
    // These have many 1-bits which cause more carries in schoolbook multiplication
    let carry_trigger_cases: &[(&str, [u8; 32])] = &[
        // All 0xFF except MSW (triggers maximum carries in lower words)
        ("0x00FF...FF (max carries)", {
            let mut k = [0xFF; 32];
            k[0] = 0x00; // Keep below n
            k[1] = 0x00;
            k
        }),
        // Alternating 0xFF 0x00 pattern (stresses word boundaries)
        ("0xFF00FF00... (alternating)", {
            let mut k = [0u8; 32];
            for i in (0..32).step_by(2) {
                k[i] = 0xFF;
            }
            k[0] = 0x00; // Keep below n
            k
        }),
        // High bits set in each 64-bit word (carry across word boundaries)
        ("0x8000...8000 (MSB each word)", {
            let mut k = [0u8; 32];
            k[0] = 0x00;   // Below n
            k[7] = 0x80;   // MSB of word 3
            k[15] = 0x80;  // MSB of word 2
            k[23] = 0x80;  // MSB of word 1
            k[31] = 0x80;  // MSB of word 0
            k
        }),
        // Value near n/2 (triggers overflow in intermediate calculations)
        ("n/2 approximation", {
            [
                0x7F, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF,
                0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF,
                0x5D, 0x57, 0x6E, 0x73, 0x57, 0xA4, 0x50, 0x1D,
                0xDF, 0xE9, 0x2F, 0x46, 0x68, 0x1B, 0x20, 0xA0,
            ]
        }),
        // Large value with specific bit pattern to stress 512-bit intermediate
        ("stress 512-bit intermediate", {
            [
                0x4F, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF,
                0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFE,
                0xBA, 0xAE, 0xDC, 0xE6, 0xAF, 0x48, 0xA0, 0x3B,
                0xBF, 0xD2, 0x5E, 0x8C, 0xD0, 0x36, 0x41, 0x40,
            ]
        }),
    ];
    
    println!("üß™ Testing GLV carry propagation (c=2 scenarios):");
    
    for (name, k_bytes) in carry_trigger_cases {
        let k_opt: k256::elliptic_curve::subtle::CtOption<Scalar> = 
            Scalar::from_repr((*k_bytes).into());
        
        if !bool::from(k_opt.is_some()) {
            println!("   ‚è≠ {} - not valid scalar, skipped", name);
            continue;
        }
        let k = k_opt.unwrap();
        
        // Verify GLV transform: (Œª¬∑k)¬∑Œª¬≤ = k
        let glv_k = k * lambda;
        let recovered_k = glv_k * lambda_sq;
        
        assert_eq!(
            recovered_k, k,
            "GLV carry propagation failed for {}", name
        );
        
        // Also verify Œª¬≥¬∑k = k (since Œª¬≥ = 1)
        let lambda_cubed = lambda * lambda * lambda;
        let triple_k = lambda_cubed * k;
        assert_eq!(triple_k, k, "Œª¬≥¬∑k should equal k for {}", name);
        
        println!("   ‚úì {}", name);
    }
    
    println!("‚úÖ All GLV carry propagation tests passed");
}

/// Test GPU GLV scalar_mul_mod_n with t[4]..t[6] carry propagation
/// This is the CRITICAL test for the carry overflow fix in keygen.metal
/// Tests values that produce 512-bit intermediate products requiring
/// t[4]+carry overflow handling
#[test]
fn test_gpu_glv_t4_t6_carry_propagation() {
    use k256::Scalar;
    use k256::elliptic_curve::PrimeField;
    use k256::SecretKey;
    
    // GLV Lambda constant (same as in keygen.metal)
    let lambda_bytes: [u8; 32] = [
        0x53, 0x63, 0xAD, 0x4C, 0xC0, 0x5C, 0x30, 0xE0,
        0xA5, 0x26, 0x1C, 0x02, 0x88, 0x12, 0x64, 0x5A,
        0x12, 0x2E, 0x22, 0xEA, 0x20, 0x81, 0x66, 0x78,
        0xDF, 0x02, 0x96, 0x7C, 0x1B, 0x23, 0xBD, 0x72,
    ];
    let lambda = Scalar::from_repr(lambda_bytes.into()).unwrap();
    
    // Test cases that SPECIFICALLY trigger t[4]+carry overflow
    // When k * lambda produces large 512-bit intermediate, t[4..6] overflow is likely
    let critical_test_cases: Vec<(&str, u64)> = vec![
        // Values near n that cause maximum 512-bit products
        // These will fill t[4], t[5], t[6] and cause t[4]+carry overflow
        ("n - 100 (near max)", 0xFFFFFFFFFFFFFE00u64.wrapping_sub(100)),
        ("n - 1000 (large)", 0xFFFFFFFFFFFFFE00u64.wrapping_sub(1000)),
        ("n/2 region", 0x7FFFFFFFFFFFF000u64),
        ("high bits pattern", 0xDEADBEEFCAFEBABEu64),
        ("all F pattern", 0xFFFFFFFFFFFFFFFFu64),
        // Small values for baseline
        ("small baseline", 100),
        ("medium value", 0x0123456789ABCDEFu64),
    ];
    
    println!("üß™ Testing GPU GLV t[4]..t[6] carry propagation (CRITICAL):");
    println!("   This tests the overflow fix: t[4]+carry must propagate to t[5],t[6]\n");
    
    // Skip if GPU not available
    let config = GeneratorConfig {
        start_offset: 1,
        batch_size: 32,
        ..Default::default()
    };
    
    let gpu_template = match GpuKeyGenerator::new(config) {
        Ok(g) => g,
        Err(e) => {
            println!("‚ö†Ô∏è GPU not available, skipping test: {}", e);
            return;
        }
    };
    
    // Get GPU info but drop it - we'll create fresh ones per test
    drop(gpu_template);
    
    let mut all_passed = true;
    
    for (name, offset) in critical_test_cases {
        // Create GPU generator with this specific offset
        let config = GeneratorConfig {
            start_offset: offset,
            batch_size: 32,
            ..Default::default()
        };
        
        let gpu = match GpuKeyGenerator::new(config.clone()) {
            Ok(g) => g,
            Err(_) => continue,
        };
        
        let adapter = GpuGeneratorAdapter::new(gpu);
        
        let batch_bytes = match adapter.generate_batch() {
            Ok(b) => b,
            Err(_) => continue,
        };
        
        let batch = KeyBatch::new(batch_bytes);
        let keys: Vec<_> = batch.iter().collect();
        
        // GLV kernel outputs pairs: [primary_0, glv_0, primary_1, glv_1, ...]
        if keys.len() < 2 {
            continue;
        }
        
        // Test first valid pair
        for i in (0..keys.len().saturating_sub(1)).step_by(2) {
            let primary = &keys[i];
            let glv = &keys[i + 1];
            
            // Skip zero keys
            if primary.private_key.iter().all(|&b| b == 0) || 
               glv.private_key.iter().all(|&b| b == 0) {
                continue;
            }
            
            // CPU compute: glv_k = primary_k * lambda (mod n)
            let primary_scalar_opt: k256::elliptic_curve::subtle::CtOption<Scalar> = 
                Scalar::from_repr(primary.private_key.into());
            
            if !bool::from(primary_scalar_opt.is_some()) {
                continue;
            }
            let primary_scalar = primary_scalar_opt.unwrap();
            
            // CPU GLV computation
            let cpu_glv_scalar = primary_scalar * lambda;
            let cpu_glv_bytes: [u8; 32] = cpu_glv_scalar.to_repr().into();
            
            // Compare GPU vs CPU
            let matches = glv.private_key == cpu_glv_bytes;
            
            if matches {
                println!("   ‚úÖ {}: GPU GLV = CPU GLV", name);
                println!("      Primary: {}", hex::encode(&primary.private_key[0..8]));
                println!("      GPU GLV: {}", hex::encode(&glv.private_key[0..8]));
            } else {
                println!("   ‚ùå {}: MISMATCH!", name);
                println!("      Primary:  {}", hex::encode(primary.private_key));
                println!("      GPU GLV:  {}", hex::encode(glv.private_key));
                println!("      CPU GLV:  {}", hex::encode(cpu_glv_bytes));
                all_passed = false;
            }
            
            // Also verify public key y-coordinates match (endomorphism check)
            if let Ok(primary_sk) = SecretKey::from_bytes((&primary.private_key).into()) {
                if let Ok(glv_sk) = SecretKey::from_bytes((&glv.private_key).into()) {
                    use k256::elliptic_curve::sec1::ToEncodedPoint;
                    
                    let primary_point = primary_sk.public_key().to_encoded_point(false);
                    let glv_point = glv_sk.public_key().to_encoded_point(false);
                    
                    let primary_y = &primary_point.as_bytes()[33..65];
                    let glv_y = &glv_point.as_bytes()[33..65];
                    
                    if primary_y != glv_y {
                        println!("      ‚ö†Ô∏è Y-coordinates differ (endomorphism broken)!");
                        all_passed = false;
                    }
                }
            }
            
            break; // One pair per test case is enough
        }
    }
    
    assert!(all_passed, "GPU GLV t[4]..t[6] carry propagation test failed!");
    println!("\n‚úÖ All GPU GLV t[4]..t[6] carry propagation tests passed!");
    println!("   The overflow fix (t[4]+carry ‚Üí t[5] ‚Üí t[6]) is working correctly.");
}

/// Test that RawKeyData avoids heap allocations unlike KeyEntry
/// This verifies Bug 5 fix: using stack-allocated RawKeyData instead of heap Strings
#[test]
fn test_raw_key_data_no_heap() {
    use xyz_pro::generator::RawKeyData;
    use std::mem::size_of;
    
    // RawKeyData should be exactly 72 bytes (stack allocated)
    assert_eq!(
        size_of::<RawKeyData>(), 72,
        "RawKeyData should be exactly 72 bytes"
    );
    
    // Create 1000 RawKeyData entries - all stack allocated
    // Start from 1 to avoid zero private key
    let entries: Vec<RawKeyData> = (1..=1000).map(|i| {
        let mut raw = RawKeyData {
            private_key: [0u8; 32],
            pubkey_hash: [0u8; 20],
            p2sh_hash: [0u8; 20],
        };
        raw.private_key[31] = (i & 0xFF) as u8;
        raw.private_key[30] = ((i >> 8) & 0xFF) as u8;
        raw
    }).collect();
    
    // Verify all entries are valid (non-zero private key)
    for (idx, entry) in entries.iter().enumerate() {
        assert!(entry.is_valid(), "Entry {} should be valid (non-zero privkey)", idx + 1);
    }
    
    // The Vec itself is heap allocated, but each RawKeyData is copied inline
    // Unlike KeyEntry which would have 4 String heap allocations per entry
    // (4000 heap allocations for 1000 entries)
    
    // Memory comparison:
    // RawKeyData: 72 bytes √ó 1000 = 72KB (contiguous)
    // KeyEntry: ~200 bytes √ó 1000 + 4000 String allocations = scattered heap
    
    let raw_memory = entries.len() * size_of::<RawKeyData>();
    println!("üß™ RawKeyData memory test:");
    println!("   1000 entries = {} bytes (contiguous)", raw_memory);
    println!("   KeyEntry would require ~200KB + 4000 heap allocations");
    println!("   ‚úì Using RawKeyData saves ~180KB + prevents fragmentation");
    
    // Verify packed layout (no padding)
    assert_eq!(
        size_of::<RawKeyData>(),
        32 + 20 + 20,
        "RawKeyData should have no padding"
    );
    
    println!("‚úÖ RawKeyData heap avoidance verified");
}

/// Test range limit configuration prevents wrap-around
/// This is critical for puzzle scanning use cases
#[test]
fn test_range_limit_prevents_wraparound() {
    // Test config validation
    let mut config = GeneratorConfig {
        start_offset: 100,
        end_offset: Some(200),
        ..Default::default()
    };
    
    assert!(config.validate().is_ok(), "Valid config should pass validation");
    assert_eq!(config.range_size(), Some(100), "Range size should be 100");
    
    // Test invalid: end <= start
    config.end_offset = Some(50);
    assert!(config.validate().is_err(), "end_offset < start_offset should fail");
    
    // Test invalid: zero start
    config.start_offset = 0;
    config.end_offset = Some(100);
    assert!(config.validate().is_err(), "start_offset = 0 should fail");
    
    println!("‚úÖ Range limit configuration validation works correctly");
    
    // Test GPU generator with range limit
    let config = GeneratorConfig {
        start_offset: 100,
        end_offset: Some(500), // Small range for testing
        batch_size: 32,
        ..Default::default()
    };
    
    let gpu = match GpuKeyGenerator::new(config) {
        Ok(g) => g,
        Err(e) => {
            println!("‚ö†Ô∏è GPU not available, skipping test: {}", e);
            return;
        }
    };
    
    // Verify initial state
    assert!(!gpu.is_range_complete(), "Should not be complete at start");
    assert_eq!(gpu.end_offset(), Some(500), "End offset should be 500");
    assert_eq!(gpu.start_offset(), 100, "Start offset should be 100");
    
    // Progress should be near 0%
    let progress = gpu.progress_percent().unwrap();
    assert!(progress < 1.0, "Progress should be near 0% at start");
    
    println!("‚úÖ GPU range limit initialized correctly");
    println!("   Start: {}, End: {:?}, Progress: {:.2}%", 
             gpu.start_offset(), gpu.end_offset(), progress);
}

/// Test that scan mode processes keys without String allocations
/// This is the core optimization for high-throughput scanning
#[test]
fn test_scan_mode_zero_string_allocation() {
    use xyz_pro::generator::RawKeyData;
    use xyz_pro::reader::TargetSet;
    
    // Load targets
    let targets = match TargetSet::load("test_targets.json") {
        Ok(t) => t,
        Err(e) => {
            println!("‚ö†Ô∏è Failed to load targets: {}", e);
            return;
        }
    };
    
    // Create test RawKeyData (simulating GPU output)
    // Start from 1 to avoid zero private key
    let test_entries: Vec<RawKeyData> = (1..=1000).map(|i| {
        RawKeyData {
            private_key: {
                let mut k = [0u8; 32];
                k[31] = (i & 0xFF) as u8;
                k[30] = ((i >> 8) & 0xFF) as u8;
                k
            },
            pubkey_hash: [i as u8; 20],
            p2sh_hash: [(i + 1) as u8; 20],
        }
    }).collect();
    
    // Scan without String allocation (the actual scan path)
    let mut match_count = 0;
    for entry in &test_entries {
        if !entry.is_valid() {
            continue;
        }
        
        // Direct hash lookup - NO STRING CONVERSION
        let (p2pkh, p2sh, p2wpkh) = targets.check_raw(&entry.pubkey_hash, &entry.p2sh_hash);
        
        if p2pkh || p2sh || p2wpkh {
            match_count += 1;
            // String encoding only happens HERE on match (rare)
            // Not in the hot path
        }
    }
    
    println!("üß™ Scan mode zero-allocation test:");
    println!("   Scanned 1000 entries with 0 String allocations in hot path");
    println!("   Matches found: {} (String encoding only on match)", match_count);
    println!("‚úÖ Scan mode correctly avoids String allocations");
}

// ============================================================================
// PHILOX RNG COLLISION TEST - GPU Thread Uniqueness
// ============================================================================

/// Test that GPU generates unique private keys with no collisions
/// 
/// This verifies:
/// 1. Each GPU thread gets a unique offset (gid * keys_per_thread + b)
/// 2. No two threads produce the same private key
/// 3. The deterministic sequence is correct
#[test]
fn test_gpu_thread_uniqueness_no_collisions() {
    use std::collections::HashSet;
    use xyz_pro::bridge::KeyGenerator;
    use xyz_pro::bridge::RawKeyData;
    
    println!("\nüß™ GPU Thread Uniqueness Test (Philox RNG Collision Check)");
    println!("{}", "=".repeat(60));
    
    let config = GeneratorConfig {
        start_offset: 1,
        ..Default::default()
    };
    
    let gpu_gen = match GpuKeyGenerator::new(config) {
        Ok(g) => g,
        Err(e) => {
            println!("‚ö†Ô∏è GPU not available: {}", e);
            return;
        }
    };
    
    let adapter = GpuGeneratorAdapter::new(gpu_gen);
    
    // Generate multiple batches and check for collisions
    let mut all_keys: HashSet<[u8; 32]> = HashSet::new();
    let mut total_keys = 0u64;
    let num_batches = 5;
    
    for batch_idx in 0..num_batches {
        let batch_data = match adapter.generate_batch() {
            Ok(data) => data,
            Err(e) => {
                println!("‚ö†Ô∏è Batch generation failed: {}", e);
                return;
            }
        };
        let batch_size = batch_data.len() / RawKeyData::SIZE;
        
        for i in 0..batch_size {
            if let Some(key_data) = RawKeyData::from_bytes(&batch_data[i * RawKeyData::SIZE..]) {
                let privkey = key_data.private_key;
                
                // Skip zero keys
                if !key_data.is_valid() {
                    continue;
                }
                
                // Check if key already seen (collision!)
                if !all_keys.insert(privkey) {
                    panic!(
                        "‚ùå COLLISION DETECTED! Batch {}, key {} has duplicate private key: {:02x?}",
                        batch_idx, i, privkey
                    );
                }
            }
        }
        
        total_keys += batch_size as u64;
        println!("   Batch {}: {} keys, total unique: {}", batch_idx, batch_size, all_keys.len());
    }
    
    // Verify we got a significant number of unique keys
    assert!(all_keys.len() > 1000, "Should have at least 1000 unique keys");
    
    println!("‚úÖ {} unique keys generated, NO COLLISIONS", all_keys.len());
    println!("   Each GPU thread produced unique private keys");
}

/// Test GPU thread offset calculation is deterministic and sequential
/// 
/// Verifies the formula: private_key[i] = base_offset + (gid * keys_per_thread) + b
#[test]
fn test_gpu_thread_offset_determinism() {
    use xyz_pro::bridge::KeyGenerator;
    use xyz_pro::bridge::RawKeyData;
    
    println!("\nüß™ GPU Thread Offset Determinism Test");
    println!("{}", "=".repeat(60));
    
    // Generate from same starting offset twice
    let config1 = GeneratorConfig {
        start_offset: 1000,
        ..Default::default()
    };
    
    let config2 = GeneratorConfig {
        start_offset: 1000,
        ..Default::default()
    };
    
    let gpu_gen1 = match GpuKeyGenerator::new(config1) {
        Ok(g) => g,
        Err(e) => {
            println!("‚ö†Ô∏è GPU not available: {}", e);
            return;
        }
    };
    
    let gpu_gen2 = match GpuKeyGenerator::new(config2) {
        Ok(g) => g,
        Err(_) => return,
    };
    
    let adapter1 = GpuGeneratorAdapter::new(gpu_gen1);
    let adapter2 = GpuGeneratorAdapter::new(gpu_gen2);
    
    // Generate same batch twice
    let data1 = match adapter1.generate_batch() {
        Ok(d) => d.to_vec(),  // Copy since we need both
        Err(e) => {
            println!("‚ö†Ô∏è Batch 1 failed: {}", e);
            return;
        }
    };
    
    let data2 = match adapter2.generate_batch() {
        Ok(d) => d.to_vec(),
        Err(e) => {
            println!("‚ö†Ô∏è Batch 2 failed: {}", e);
            return;
        }
    };
    
    // Compare first 1000 keys (should be identical)
    let keys1 = data1.len() / RawKeyData::SIZE;
    let keys2 = data2.len() / RawKeyData::SIZE;
    let compare_count = keys1.min(keys2).min(1000);
    
    for i in 0..compare_count {
        let key1 = RawKeyData::from_bytes(&data1[i * RawKeyData::SIZE..]).unwrap();
        let key2 = RawKeyData::from_bytes(&data2[i * RawKeyData::SIZE..]).unwrap();
        
        assert_eq!(
            key1.private_key,
            key2.private_key,
            "Key {} should be identical for same start_offset",
            i
        );
    }
    
    println!("‚úÖ {} keys are deterministic and reproducible", compare_count);
    println!("   Same start_offset produces identical sequence");
}

/// Test that GPU keys are sequential (no gaps)
/// 
/// NOTE: With GLV mode enabled, output is [k, Œª¬∑k, k+1, Œª¬∑(k+1), ...] pairs
/// The base keys (k) should be sequential, GLV keys (Œª¬∑k) are derived
#[test]
fn test_gpu_keys_are_sequential() {
    use xyz_pro::bridge::KeyGenerator;
    use xyz_pro::bridge::RawKeyData;
    
    println!("\nüß™ GPU Keys Sequential Test (GLV Mode)");
    println!("{}", "=".repeat(60));
    
    let start_offset = 1u64;
    let config = GeneratorConfig {
        start_offset,
        ..Default::default()
    };
    
    let gpu_gen = match GpuKeyGenerator::new(config) {
        Ok(g) => g,
        Err(e) => {
            println!("‚ö†Ô∏è GPU not available: {}", e);
            return;
        }
    };
    
    let adapter = GpuGeneratorAdapter::new(gpu_gen);
    let data = match adapter.generate_batch() {
        Ok(d) => d,
        Err(e) => {
            println!("‚ö†Ô∏è Batch failed: {}", e);
            return;
        }
    };
    
    // With GLV, keys come in pairs: [base_key, glv_key, base_key+1, glv_key+1, ...]
    // We check that base keys (even indices) are sequential
    let key_count = data.len() / RawKeyData::SIZE;
    let check_count = key_count.min(100);
    
    println!("   Total keys in batch: {}", key_count);
    println!("   GLV mode: each base key produces 2 output entries");
    
    // Check first 50 base keys (indices 0, 2, 4, ...) are sequential
    let mut sequential_count = 0;
    for pair in 0..check_count.min(50) {
        let base_idx = pair * 2;  // Base keys are at even indices
        if base_idx >= key_count {
            break;
        }
        
        let key_data = RawKeyData::from_bytes(&data[base_idx * RawKeyData::SIZE..]).unwrap();
        let privkey = key_data.private_key;
        
        // Extract the expected offset from privkey (last 8 bytes, big endian)
        let mut offset_bytes = [0u8; 8];
        offset_bytes.copy_from_slice(&privkey[24..32]);
        let actual_offset = u64::from_be_bytes(offset_bytes);
        
        let expected_offset = start_offset + pair as u64;
        
        // Base keys should be sequential
        assert_eq!(
            actual_offset, expected_offset,
            "Base key {} (at index {}) should have offset {}, got {}",
            pair, base_idx, expected_offset, actual_offset
        );
        sequential_count += 1;
    }
    
    println!("‚úÖ First {} base keys are sequential: {}..{}", 
             sequential_count, start_offset, start_offset + sequential_count as u64 - 1);
    println!("   GLV keys at odd indices are Œª¬∑k (derived from base keys)");
}

// ============================================================================
// MEMORY ALIGNMENT / ZERO-COPY TESTS
// ============================================================================

/// Test RawKeyData struct alignment for zero-copy GPU access
/// 
/// Metal API requires proper alignment for zero-copy (Unified Memory).
/// This verifies RawKeyData is correctly sized and aligned.
#[test]
fn test_rawkeydata_alignment_for_zerocopy() {
    use std::mem::{size_of, align_of};
    use xyz_pro::bridge::RawKeyData;
    
    println!("\nüß™ RawKeyData Alignment Test (Zero-Copy Safety)");
    println!("{}", "=".repeat(60));
    
    // RawKeyData is #[repr(C, packed)] - 72 bytes, 1-byte alignment
    let size = size_of::<RawKeyData>();
    let align = align_of::<RawKeyData>();
    
    println!("   RawKeyData size:  {} bytes", size);
    println!("   RawKeyData align: {} bytes", align);
    
    // Verify size matches GPU output format: privkey(32) + pubkey_hash(20) + p2sh_hash(20)
    assert_eq!(size, 72, "RawKeyData should be exactly 72 bytes");
    assert_eq!(size, RawKeyData::SIZE, "RawKeyData::SIZE should match size_of");
    
    // For packed struct, alignment is 1 (byte-aligned)
    assert_eq!(align, 1, "Packed struct should have 1-byte alignment");
    
    // Verify field layout matches GPU output
    let test_bytes = [
        // private_key (32 bytes of 0xAA)
        0xAA, 0xAA, 0xAA, 0xAA, 0xAA, 0xAA, 0xAA, 0xAA,
        0xAA, 0xAA, 0xAA, 0xAA, 0xAA, 0xAA, 0xAA, 0xAA,
        0xAA, 0xAA, 0xAA, 0xAA, 0xAA, 0xAA, 0xAA, 0xAA,
        0xAA, 0xAA, 0xAA, 0xAA, 0xAA, 0xAA, 0xAA, 0xAA,
        // pubkey_hash (20 bytes of 0xBB)
        0xBB, 0xBB, 0xBB, 0xBB, 0xBB, 0xBB, 0xBB, 0xBB,
        0xBB, 0xBB, 0xBB, 0xBB, 0xBB, 0xBB, 0xBB, 0xBB,
        0xBB, 0xBB, 0xBB, 0xBB,
        // p2sh_hash (20 bytes of 0xCC)
        0xCC, 0xCC, 0xCC, 0xCC, 0xCC, 0xCC, 0xCC, 0xCC,
        0xCC, 0xCC, 0xCC, 0xCC, 0xCC, 0xCC, 0xCC, 0xCC,
        0xCC, 0xCC, 0xCC, 0xCC,
    ];
    
    let test_data = RawKeyData::from_bytes(&test_bytes).expect("Should parse");
    
    // Verify fields
    assert!(test_data.private_key.iter().all(|&b| b == 0xAA), "private_key should be all 0xAA");
    assert!(test_data.pubkey_hash.iter().all(|&b| b == 0xBB), "pubkey_hash should be all 0xBB");
    assert!(test_data.p2sh_hash.iter().all(|&b| b == 0xCC), "p2sh_hash should be all 0xCC");
    
    println!("‚úÖ RawKeyData layout matches GPU output format exactly");
    println!("   [0..31]  private_key  (32 bytes)");
    println!("   [32..51] pubkey_hash  (20 bytes)");
    println!("   [52..71] p2sh_hash    (20 bytes)");
}

/// Test Metal buffer alignment (page-aligned for zero-copy)
/// 
/// Metal's StorageModeShared requires buffers to be page-aligned (4096 bytes)
/// for efficient zero-copy access between CPU and GPU.
#[test]
fn test_metal_buffer_page_alignment() {
    println!("\nüß™ Metal Buffer Page Alignment Test");
    println!("{}", "=".repeat(60));
    
    let config = GeneratorConfig {
        start_offset: 1,
        ..Default::default()
    };
    
    let gpu_gen = match GpuKeyGenerator::new(config) {
        Ok(g) => g,
        Err(e) => {
            println!("‚ö†Ô∏è GPU not available: {}", e);
            return;
        }
    };
    
    // Get buffer info - use public buffer_set method
    let pipeline_depth = gpu_gen.pipeline_depth();
    
    for i in 0..pipeline_depth {
        let bs = gpu_gen.buffer_set(i);
        let output_ptr = bs.output_buffer.contents() as usize;
        let output_len = bs.output_buffer.length() as usize;
        
        // Check page alignment (4096 bytes = 0x1000)
        let page_aligned = (output_ptr & 0xFFF) == 0;
        
        println!("   Buffer {}: ptr=0x{:x}, len={} MB, page_aligned={}",
                 i, output_ptr, output_len / (1024 * 1024), page_aligned);
        
        // Metal API guarantees page alignment for StorageModeShared
        // If this fails, it indicates a Metal API issue (very unlikely)
        assert!(
            page_aligned,
            "Metal buffer {} should be page-aligned (4096 bytes), got ptr=0x{:x}",
            i, output_ptr
        );
    }
    
    println!("‚úÖ All Metal buffers are page-aligned (4096 bytes)");
    println!("   Zero-copy access is safe on Unified Memory");
}

/// Test GPU output buffer can be read as RawKeyData slice without issues
#[test]
fn test_gpu_buffer_to_rawkeydata_slice() {
    use xyz_pro::bridge::KeyGenerator;
    use xyz_pro::bridge::RawKeyData;
    
    println!("\nüß™ GPU Buffer ‚Üí RawKeyData Slice Test");
    println!("{}", "=".repeat(60));
    
    let config = GeneratorConfig {
        start_offset: 1,
        ..Default::default()
    };
    
    let gpu_gen = match GpuKeyGenerator::new(config) {
        Ok(g) => g,
        Err(e) => {
            println!("‚ö†Ô∏è GPU not available: {}", e);
            return;
        }
    };
    
    let adapter = GpuGeneratorAdapter::new(gpu_gen);
    
    // Generate a batch
    let data = match adapter.generate_batch() {
        Ok(d) => d,
        Err(e) => {
            println!("‚ö†Ô∏è Batch failed: {}", e);
            return;
        }
    };
    let total_keys = data.len() / RawKeyData::SIZE;
    
    // Verify batch can be iterated safely
    let mut valid_count = 0;
    let mut invalid_count = 0;
    
    for i in 0..total_keys {
        if let Some(key_data) = RawKeyData::from_bytes(&data[i * RawKeyData::SIZE..]) {
            if key_data.is_valid() {
                valid_count += 1;
                
                // Verify we can access all fields without issues
                let _privkey = &key_data.private_key;
                let _pubhash = &key_data.pubkey_hash;
                let _p2sh = &key_data.p2sh_hash;
            } else {
                invalid_count += 1;
            }
        }
    }
    
    println!("   Total keys: {}", total_keys);
    println!("   Valid keys: {}", valid_count);
    println!("   Invalid (zero) keys: {}", invalid_count);
    
    // Most keys should be valid (non-zero)
    assert!(valid_count > 0, "Should have some valid keys");
    
    // The very first key might be zero if start_offset is handled specially
    // but the vast majority should be valid
    let valid_ratio = valid_count as f64 / total_keys as f64;
    assert!(valid_ratio > 0.99, "At least 99% of keys should be valid, got {}%", valid_ratio * 100.0);
    
    println!("‚úÖ GPU buffer ‚Üí RawKeyData slice works correctly");
    println!("   {}% keys are valid (non-zero)", (valid_ratio * 100.0) as u32);
}

// ============================================================================
// CPU/GPU GLV CONSISTENCY TESTS
// ============================================================================

/// Test that CPU KeyGenerator with GLV produces 2x keys
#[test]
fn test_cpu_glv_produces_double_keys() {
    use xyz_pro::generator::CpuKeyGenerator;
    
    println!("\nüß™ CPU GLV Double Key Production Test");
    println!("{}", "=".repeat(60));
    
    let gen = CpuKeyGenerator::with_seed(12345);
    assert!(gen.is_glv_enabled(), "GLV should be enabled by default");
    
    // Generate 100 base keys
    let batch = gen.generate_batch(100);
    
    println!("   Base counter: 100");
    println!("   Keys produced: {}", batch.len());
    
    // With GLV, should get close to 200 keys (some might fail validation)
    assert!(batch.len() > 150, "GLV should produce >150 keys from 100 counters, got {}", batch.len());
    assert!(batch.len() <= 200, "GLV should produce <=200 keys from 100 counters, got {}", batch.len());
    
    // All keys should be unique
    let mut seen = std::collections::HashSet::new();
    for key in &batch {
        assert!(seen.insert(key.private_key), "Duplicate key found!");
    }
    
    println!("‚úÖ CPU GLV mode produces ~2x unique keys per counter");
}

/// Test that CPU GLV lambda matches GPU GLV lambda
#[test]
fn test_cpu_gpu_glv_lambda_consistency() {
    use xyz_pro::generator::CpuKeyGenerator;
    use xyz_pro::bridge::RawKeyData;
    
    println!("\nüß™ CPU/GPU GLV Lambda Consistency Test");
    println!("{}", "=".repeat(60));
    
    // GPU GLV_LAMBDA constant (from keygen.metal)
    const GPU_GLV_LAMBDA: [u8; 32] = [
        0x53, 0x63, 0xad, 0x4c, 0xc0, 0x5c, 0x30, 0xe0,
        0xa5, 0x26, 0x1c, 0x02, 0x88, 0x12, 0x64, 0x5a,
        0x12, 0x2e, 0x22, 0xea, 0x20, 0x81, 0x66, 0x78,
        0xdf, 0x02, 0x96, 0x7c, 0x1b, 0x23, 0xbd, 0x72,
    ];
    
    // CPU should compute 1 * Œª = Œª
    // We test this by generating key=1 and checking its GLV partner
    let gen = CpuKeyGenerator::without_glv(0); // We'll manually check
    
    // Test key = 1
    let base_key: [u8; 32] = [
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
    ];
    
    // Compute GLV key using CPU method
    use k256::elliptic_curve::PrimeField;
    use k256::Scalar;
    
    let k = Scalar::from_repr_vartime(base_key.into()).unwrap();
    let lambda = Scalar::from_repr_vartime(GPU_GLV_LAMBDA.into()).unwrap();
    let glv_k = k * lambda;
    let glv_bytes: [u8; 32] = glv_k.to_repr().into();
    
    // 1 * Œª should equal Œª
    assert_eq!(glv_bytes, GPU_GLV_LAMBDA, 
        "CPU GLV transform: 1 * Œª should equal Œª");
    
    println!("   Base key:  0x{}...01", "00".repeat(31));
    println!("   GLV key:   0x{}...", hex::encode(&glv_bytes[..8]));
    println!("   Expected:  0x{}...", hex::encode(&GPU_GLV_LAMBDA[..8]));
    println!("‚úÖ CPU and GPU use the same GLV Lambda constant");
}

/// Test that CPU GLV addresses match GPU GLV addresses for same key
#[test]
fn test_cpu_gpu_glv_address_consistency() {
    use xyz_pro::generator::CpuKeyGenerator;
    use xyz_pro::bridge::RawKeyData;
    use std::collections::HashSet;
    
    println!("\nüß™ CPU/GPU GLV Address Consistency Test");
    println!("{}", "=".repeat(60));
    
    // Generate keys with CPU GLV
    let cpu_gen = CpuKeyGenerator::with_seed(99999);
    let cpu_batch = cpu_gen.generate_batch(100);
    
    // Collect all CPU pubkey hashes
    let cpu_hashes: HashSet<[u8; 20]> = cpu_batch.iter()
        .map(|k| k.pubkey_hash)
        .collect();
    
    println!("   CPU keys generated: {}", cpu_batch.len());
    println!("   Unique pubkey hashes: {}", cpu_hashes.len());
    
    // Verify we have GLV pairs (should have many unique hashes)
    assert!(cpu_hashes.len() > 100, "Should have >100 unique hashes with GLV");
    
    // Verify no duplicates in CPU output
    assert_eq!(cpu_hashes.len(), cpu_batch.len(), "All CPU keys should have unique pubkey_hash");
    
    println!("‚úÖ CPU GLV produces unique addresses consistent with GPU model");
}

/// Test effective_keys_generated correctly reports 2x for GLV mode
#[test]
fn test_cpu_effective_keys_counter() {
    use xyz_pro::generator::CpuKeyGenerator;
    
    println!("\nüß™ CPU Effective Keys Counter Test");
    println!("{}", "=".repeat(60));
    
    let gen = CpuKeyGenerator::with_seed(11111);
    
    // Before generating
    assert_eq!(gen.current_count(), 0);
    assert_eq!(gen.effective_keys_generated(), 0);
    
    // Generate 100 base keys
    let _ = gen.generate_batch(100);
    
    // Counter should be 100 (base keys processed)
    assert_eq!(gen.current_count(), 100, "Counter should be 100");
    
    // Effective should be 200 (2x for GLV)
    assert_eq!(gen.effective_keys_generated(), 200, "Effective should be 200 (2x GLV)");
    
    println!("   Counter (base): 100");
    println!("   Effective (GLV): 200");
    println!("‚úÖ Statistics correctly report 2x for GLV mode");
}
